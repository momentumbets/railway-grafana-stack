
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  http {
    endpoint = "0.0.0.0:4318"
  }
  output {
    metrics = [otelcol.processor.batch.all_signals.input]
    logs    = [otelcol.processor.batch.all_signals.input]
    traces  = [otelcol.processor.batch.all_signals.input]
  }
}

otelcol.processor.batch "all_signals" {
  output {
    metrics = [otelcol.exporter.prometheus.otlp_metrics_out.input]
    logs    = [otelcol.exporter.loki.otlp_logs_out.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = sys.env("TEMPO_INTERNAL_URL") + "/v1/traces"
  }
}

otelcol.exporter.prometheus "otlp_metrics_out" {
  forward_to = [prometheus.remote_write.otlp_metrics.receiver]
}

prometheus.remote_write "otlp_metrics" {
	external_labels = {
		monitor = "railway-prom-otlp",
		source    = "otelcol",
	}

	endpoint {
		url = sys.env("PROMETHEUS_INTERNAL_URL") + "/api/v1/write"

		queue_config { }

		metadata_config { }
	}
}

otelcol.exporter.loki "otlp_logs_out" {
  forward_to = [loki.write.otlp_logs.receiver]
}

loki.write "otlp_logs" {
  endpoint {
    url = sys.env("LOKI_INTERNAL_URL") + "/api/v1/push"
  }
}

// Existing Prometheus and Loki configurations remain as they are
prometheus.relabel "filter_metrics" {
	forward_to = [prometheus.remote_write.default.receiver,prometheus.remote_write.selfhosted.receiver, prometheus.remote_write.otlp_metrics.receiver]

	// Drop metrics you don't want
	rule {
		source_labels = ["__name__"]
		regex         = "(criteria_eval_related_rec_.*)"
		action        = "drop"
	}
}

prometheus.scrape "prometheus" {
	targets = [{
		__address__ = "localhost:9090",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "prometheus"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
}

prometheus.scrape "server" {
	targets = [{
		__address__ = "mb-stack.railway.internal:3001",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "server"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "queues" {
	targets = [{
		__address__ = "mb-stack.railway.internal:3001",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "queues"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/queues/metrics"
}

prometheus.scrape "criteria_evaluator" {
	targets = [{
		__address__ = "criteria-evaluator.railway.internal:3003",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "criteria-evaluator"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "bull_queue_monitor" {
	targets = [{
		__address__ = "bull-queue-monitor.railway.internal:3000",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "bull-queues"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/metrics"
}

prometheus.remote_write "default" {
	external_labels = {
		monitor = "railway-prom",
	}

	endpoint {
		url = "https://prometheus-prod-13-prod-us-east-0.grafana.net/api/prom/push"

		basic_auth {
			username = "1763099"
			password = sys.env("GRAFANA_CLOUD_PW")
		}

		queue_config { }

		metadata_config { }
	}
}


loki.write "grafanacloud" {
  endpoint {
    url = "https://logs-prod-006.grafana.net/loki/api/v1/push"

    basic_auth {
      username = "981018"
      password = sys.env("GRAFANA_CLOUD_PW")
    }
  }
}



prometheus.remote_write "selfhosted" {
	external_labels = {
		monitor = "railway-prom",
	}

	endpoint {
		url = sys.env("PROMETHEUS_INTERNAL_URL") + "/api/v1/write"

		queue_config { }

		metadata_config { }
	}
}

loki.source.api "listener" {
    http {
        listen_address = "0.0.0.0"
        listen_port    = 3100
    }
    labels = { "source" = "api" }
    forward_to = [loki.write.selfhosted.receiver]
}

loki.write "selfhosted" {
    endpoint {
        url = sys.env("LOKI_INTERNAL_URL") + "api/v1/push"
    }
}
