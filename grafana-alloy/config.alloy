
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  http {
    endpoint = "0.0.0.0:4318"
  }
  output {
    metrics = [otelcol.processor.batch.all_signals.input]
    logs    = [otelcol.processor.batch.all_signals.input]
    traces  = [otelcol.processor.batch.all_signals.input]
  }
}

otelcol.processor.batch "all_signals" {
  output {
    metrics = [otelcol.exporter.prometheus.otlp_metrics_out.input]
    logs    = [otelcol.exporter.loki.otlp_logs_out.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = sys.env("TEMPO_INTERNAL_URL") + "/v1/traces"
  }
}

otelcol.exporter.prometheus "otlp_metrics_out" {
  forward_to = [prometheus.relabel.filter_metrics.receiver]
}

otelcol.exporter.loki "otlp_logs_out" {
  forward_to = [loki.write.selfhosted.receiver]
}


// Existing Prometheus and Loki configurations remain as they are
prometheus.relabel "filter_metrics" {
	forward_to = [prometheus.remote_write.selfhosted.receiver]

	// Drop metrics you don't want
	rule {
		source_labels = ["__name__"]
		regex         = "(criteria_eval_related_rec_.*)"
		action        = "drop"
	}
}

prometheus.scrape "prometheus" {
	targets = [{
		__address__ = "localhost:9090",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "prometheus"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
}

prometheus.scrape "grafana" {
	targets = [{
		__address__ = "grafana-28261f21.railway.internal:8080",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "grafana"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/metrics"
}


prometheus.scrape "server" {
	targets = [{
		__address__ = "server.railway.internal:3001",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "server"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "queues" {
	targets = [{
		__address__ = "server.railway.internal:3001",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "queues"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/queues/metrics"
}

prometheus.scrape "odds_ingestion" {
	targets = [{
		__address__ = "odds-ingestion.railway.internal:3005",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "odds_ingestion"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "criteria_evaluator" {
	targets = [{
		__address__ = "criteria-evaluator.railway.internal:3003",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "criteria-evaluator"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "sports_scanner" {
	targets = [{
		__address__ = "sports-scanner.railway.internal:3004",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "sports-scanner"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "notification_service" {
	targets = [{
		__address__ = "notification-service.railway.internal:3005",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "notification-service"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}

prometheus.scrape "stripe_webhooks" {
	targets = [{
		__address__ = "stripe-webhooks.railway.internal:3010",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "stripe-webhooks"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/v1/metrics"
}


prometheus.scrape "bull_queue_monitor" {
	targets = [{
		__address__ = "bull-queue-monitor.railway.internal:3000",
	}]
	forward_to      = [prometheus.relabel.filter_metrics.receiver]
	job_name        = "bull-queues"
	scrape_interval = "60s"
	scrape_timeout  = "60s"
	metrics_path    = "/metrics"
}

loki.source.api "listener" {
    http {
        listen_address = "0.0.0.0"
        listen_port    = 3100
    }
    labels = { "source" = "api" }
    forward_to = [loki.write.selfhosted.receiver]
}

loki.write "selfhosted" {
    endpoint {
        url = sys.env("LOKI_INTERNAL_URL") + "/loki/api/v1/push"
    }
}


prometheus.remote_write "selfhosted" {
	external_labels = {
		monitor = "railway-prom",
	}

	endpoint {
		url = sys.env("PROMETHEUS_INTERNAL_URL") + "/api/v1/write"

		queue_config { }

		metadata_config { }
	}
}


prometheus.exporter.postgres "integrations_postgres_exporter" {
    data_source_names = [sys.env("POSTGRES_INTERNAL_URL")]
}
discovery.relabel "integrations_postgres_exporter" {
    targets = prometheus.exporter.postgres.integrations_postgres_exporter.targets

    rule {
        target_label = "instance"
        replacement  = constants.hostname
    }
    rule {                
        target_label = "job"
        replacement  = "integrations/postgres_exporter"
    }
}
prometheus.scrape "integrations_postgres_exporter" {
    targets         = discovery.relabel.integrations_postgres_exporter.output
    forward_to      = [prometheus.relabel.filter_metrics.receiver]
    job_name        = "integrations/postgres_exporter"
    scrape_interval = "60s"
    scrape_timeout  = "60s"
}
